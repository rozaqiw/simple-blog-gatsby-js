---
date: 2019-03-25
title: 'docker快速入门'
template: post
thumbnail: '../thumbnails/docker.png'
slug: docker
categories:
  - docker
tags:
  - docker
---

## 镜像与容器的概念

镜像相当于系统光盘，是只读的。


容器是由镜像生成的docker实例，一个镜像可以生成多个容器，每个容器之间、容器与宿主之间是相互隔离的。

## 启动docker

```bash
docker run -d -t -p 8000:5000 --name demo ubuntu:18.04
```
`run`	启动一个新的容器

`-d`	让容器在后台运行	

`-t`	较少用到，让一个空白的`ubuntu`镜像在后台运行

`-p`	指定端口映射，在本机访问8000会被自动转到容器中5000端口

`--name`	指定容器名字

`ubuntu:18.04`	镜像名

## 创建两个相同端口的docker

1. 运行一个占用8000端口的容器`test1`

```bash
docker run -d -t -p 8000:5000 --name test1 ubuntu:18.04
```

2. 再运行一个占用8000端口的容器`test2`，会创建失败

```bash
docker run -d -t -p 8000:5000 --name test2 ubuntu:18.04
```

3. 删除第一个容器`test1`

```bash
docker rm -f test1
```

4. 再次运行容器`test2`，仍然失败

```bash
docker run -d -t -p 8000:5000 --name test2 ubuntu:18.04
```

因为创建容器`test2`的命令虽然运行失败，但容器其实已经生成

5. 解决方案有两种

改名字：

```bash
docker run -d -t -p 8000:5000 --name test3 ubuntu:18.04
```

删除重来：

```bash
docker rm test2
docker run -d -t -p 8000:5000 --name test2 ubuntu:18.04
```

## 在docker中安装软件

```bash
docker exec demo apt update
docker exec demo apt -y install python3 python3-pip
docker exec demo pip3 install flask
```

## 在docker中运行web文件

首先在docker中创建一个`code`文件夹
```bash
docker exec demo mkdir /code
```
使用`cp`参数，把当前文件夹的`a.py`文件拷贝到demo容器的`/code/a.py`

```bash
docker cp a.py "demo:/code/a.py"
```

**注意：**由于/code必须是容器中存在的目录，docker不会自动创建


```python
# a.py
from flask import Flask

app = Flask(__name__)

@app.route('/')
def index():
 return 'Hello from Docker'

if __name__ == "__main__":
 app.run(host="0.0.0.0", debug=True)
```



## 用脚本的方式配置容器

**注意：**`ctrl + c` 并不会终止进程，而是让其在后台运行

停止容器：

```bash
docker stop demo
```

`install.sh`脚本用于安装软件

```bash
# install.sh
apt update
apt -y install python3 python3-pip
pip3 install flask
```

`run.sh`脚本用于运行程序

```bash
# run.sh
cd /code
python3 a.py
```

## 运行脚本配置并开启新容器

```bash
docker run -d -t -p 7000:5000 --name demo1 ubuntu:18.04

docker exec demo1 mkdir /code
docker cp install.sh "demo1:/code/install.sh"
docker cp run.sh "demo1:/code/run.sh"
docker cp a.py "demo1:/code/a.py"
docker exec demo1 bash /code/install.sh
docker exec demo1 bash /code/run.sh
```

## 容器的常见操作

启动一个容器

```
docker start demo
```

查看正在运行的容器

```
docker ps
```

停止容器

```
docker stop demo
```

查看所有容器，包括未运行的

```
docker ps -a
```

删除被停止的容器和运行中的容器

```
docker rm demo
docker rm -f demo1
```

## 使用dockerfile打包一个镜像

自行编写配置文件`dockerfile`来构建镜像

```dockerfile
# 在dockerfile中 # 是注释
# FROM 用于指定构建镜像的基础镜像
FROM ubuntu:18.04

# RUN 用于在构建镜像的时候在镜像中执行命令
RUN apt update
RUN apt -y install python3 python3-pip
RUN pip3 install flask

# COPY 相当于命令的docker cp
# 把本机当前目录下的app.py 文件拷贝到镜像的/code/app.py
# 和docker cp不同的是，COPY会自动创建镜像中不存在的目录
COPY app.py /code/app.py

# WORKDIR 用于指定从镜像启动的容器内的工作目录
WORKDIR /code

# CMD 用于指定容器运行后要执行的命令和参数列表
# 这样从本镜像启动容器后会自动执行 python3 app.py 这个命令
#
# 由于我们已经用 WORKDIR 指定了容器的工作目录
# 所以下面的命令都是在 /code 下执行的
CMD ["python3", "app.py"]

# 有可能会看到 ENTRYPOINT 参数用于指定容器运行后的入口程序
# 但现在这个参数意义很小，可以忽略
```

## 使用dockerfile构建镜像

```
docker build -t webimage .
```

命令中参数 `-t webimage` 指定来镜像的名字为`webimage`，这个名字可以用于在之后从镜像启动容器

最后的 `. `用来指定构建镜像的时候的工作目录为本机当前目录

查看本机存储的镜像（包括下载的和构建的）

```bash
docker images
```

```
docker run -p 8001:5000 --name demo2 webimage
```

## 服务器docker部署

安装脚本和程序文件都放在本机app目录下，一共有3个文件

| 文件名| 说明|
| ----------------- | ------------------------------ |
| Install-docker.sh | 在ubuntu服务器安装docker的脚本 |
| Dockerfile  | dockerfile文件  |
| app.py| web程序|

使用`scp`命令把`app`拷贝到服务器中

```bash
scp -r app ubuntu@ip:/tmp
```

登录服务器

```bash
ssh username@ip
```

安装docker

```bash
sh /tmp/app/install-docker.sh
```

打包

```bash
cd /tmp/app
sudo docker build -t webimage .
```

运行docker容器

```bash
sudo docker run -d -p 8000:5000 --name serverdemo webimage
```

`install-docker.sh`文件如下

```bash
# 官方安装指南 Ubuntu 版本
# https://docs.docker.com/install/linux/docker-ce/ubuntu

sudo apt update

# docker 的源是 https，所以安装这些软件用于支持 https 的 apt 仓库
sudo apt install -y apt-transport-https ca-certificates curl software-properties-common

# 添加 Docker 的官方 GPG key
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

# 设置官方 Docker 源
sudo add-apt-repository \
"deb [arch=amd64] https://download.docker.com/linux/ubuntu \
$(lsb_release -cs) \
stable"

# 安装 Docker
sudo apt update
sudo apt install -y docker-ce

# 如果你想验证 Docker 安装好了，可以运行一个 hello-world 容器
# sudo docker run hello-world

```

## docker数据卷

两个不同的容器之间无法互通。而且，当容器被删除的时候，容器里的所有数据都会被删除。



docker推出了数据卷volume功能：

数据卷可以理解为虚拟机的虚拟磁盘，是独立于容器的文件

在容器中它被挂载为一个目录的形式

对于容器内的应用来说，数据卷是透明的，无法感知它的存在，就是一个普通的文件夹

由于数据卷独立于容器而存在，因此删除容器的时候数据卷不会受到影响



数据卷优点：

多容器可以通过挂载同一个数据卷来共享数据

数据卷可以方便地备份、存储数据

## 数据卷的使用

创建一个`volume`

```bash
docker volume create testvolume
```

列出所有数据卷

```bash
docker volume ls
```

删除一个数据卷

```bash
docker volume rm testvolume
```

在容器中使用数据卷

```bash
docker volume create web

docker run -d --name demo --mount source=web,target=/volume  webimage
```

`--mount source=web,target=/volume`是把数据卷`web`挂载到容器的`/volume`目录上

## 数据卷的特性

保存在容器上的文件，容器删除后将不存在

1. 执行命令，往/b.txt写入时间，并查看

```bash
docker exec demo sh -c 'date > /b.txt'
docker exec demo sh -c 'cat /b.txt'
```

2. 删除容器，重新启动一个同名容器，之前的容器内容已经没有了

```bash
docker rm -f demo
docker run -d --name demo --mount source=web,target=/volume webimage
docker exec demo sh -c 'cat /b.txt'
```



保存在数据卷上的文件，即使容器被删除仍然存在

1. 执行命令，往数据卷中的/b.txt写入时间，并查看

```bash
docker exec demo sh -c 'date > /volume/b.txt'
docker rm -f demo	#删除容器
docker run -d --name demo --mount source=web,target=/volume webimage
docker exec demo sh -c 'cat /volume/b.txt'
```

2. 多容器之间可以通过数据卷共享文件

```bash
docker run -d --name demo2 --mount source=web,target=/v2 webimage
docker exec demo2 sh -c 'cat /v2/b.txt'
```

## 共享目录

除了挂载数据卷外，docker还可以挂载共享目录（和虚拟机一样）

共享目录的优势是使用方便，易于理解，可以在某些场景下方便使用

（比如开发时在宿主机中修改源代码，docker中实时生效，省去build镜像的过程）

### 挂载文件目录

从`nginx`镜像运行一个名为`nginx1`的容器，设置`8080:80`的端口映射，`--mount`参数的`type=bind`表明要挂载共享目录

```bash
docker run -p 8080:80 --name nginx1 \
	--mount type=bind,source="${PWD}",target=/usr/share/nginx/html/ nginx
```

把宿主机的**当前目录**映射为容器的`/usr/share/nginx/html`（`nginx`容器的静态页面文件存放路径）

这样在宿主机中访问`localhost:8080`会自动访问宿主机当前目录下的`index.html`文件（`nginx`的默认静态文件首页）

`source`参数必须使用绝对路径，这里使用`"${PWD}"`的方式来获取Mac/Linux/Windows中获取当前目录路径（Windows下必须使用PowerShell），加引号时因为路径中可能有空格等特殊符号。

最后的`nginx`是镜像名



### 挂载单个文件

如果要挂载单个文件，一定要保证宿主机文件存在，否则这个路径会被认为是一个目录挂载

```bash
docker run -p 8001:80 --name nginx2 \
	--mount type=bind,source="${PWD}"/index.html,target=/usr/share/nginx/html/test.html nginx
```

访问 http://localhost:8081/test.html 返回的是宿主机的`index.html`文件

### 挂载多个文件

```bash
docker run -p 8002:80 --name nginx3 \
	--mount type=bind,source="${PWD}"/index.html,target=/usr/share/nginx/html/test.html \
	--mount type=bind,source="${PWD}"/test.html,target=/usr/share/nginx/html/test2.html \
	nginx
```

访问 http://localhost:8081/test.html 返回的是宿主机的index.html文件

访问 http://localhost:8081/test2.html 返回的是宿主机的test.html文件

## 使用compose部署更多应用

docker被设计为程序容器，每一个容器只应该运行一个程序。但是在实际的项目中会有需要多个程序互相配合一起运行，比如Web程序通常包含app、数据库、nginx、redis等。

这些程序各自的容器需要协同工作，并且需要能够互相访问网络，比如app需要连接数据库，nginx需要能访问app才能给它做反向代理。

由于docker容器是一个隔离的环境，正常情况下容器与容器之间是无法相互访问的。

docker官方推出了compose程序用于配置、管理多容器的运行

compose通过一个单独的`docker-compose.yml`配置文件来管理一组容器

###  安装compose

Docker在macOS和Windows中`docker-compose`是自带的，只有在Linux服务器上，需要单独安装

compose网址 https://github.com/docker/compose/releases 

```bash
sudo su
curl -L https://github.com/docker/compose/releases/download/1.24.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose
chmod +x /usr/local/bin/docker-compose
```

由于compose程序在github，安装速度可能比较慢，所以我们可以用国内的地址安装

```bash
sudo su
curl -L https://get.daocloud.io/docker/compose/releases/download/1.24.0/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose
chmod +x /usr/local/bin/docker-compose
```

官方安装指南 https://docs.docker.com/compose/install

## compose的使用

compose把一组容器作为一个项目来进行管理，并且会设置好容器间互联的内部网络

每一个容器在compose中被称为服务service，compose使用一个`docker-compose.yml`文件来描述compose项目的构建



启动项目

```bash
docker-compose up
docker-compose up -d #在后台运行
```

暂停容器的运行

```bash
docker-compose stop
```

关闭并删除项目的所有容器

```bash
docker-compose down
```



```python
# app.py
from flask import Flask
from redis import Redis


app = Flask(__name__)
# redisdemo 是 compose 中创建的主机名，由 docker-compose.yml 中指定
# compose 会给每个容器提供 DNS 服务保证容器间互相访问
redis = Redis(host='redisdemo', port=6379)


@app.route('/')
def index():
 count = redis.incr('hits')
 return 'views {}'.format(count)


if __name__ == "__main__":
 app.run(host="0.0.0.0", debug=True)
```

```yml
# docker-compose.yml
# 表示这是 compose 配置文件第三版
version: '3'

# 每个服务都是一个 Docker 容器
# 所以必须用 image 指定服务的镜像名或者从 Dockerfile 中 build 镜像
services:
  pyweb:
 # build 指定了 Dockerfile 所在的路径
 build: .
 # ports 指定暴露的端口，9000 是宿主机，5000 是容器
 # 可以指定多个暴露端口
 ports:
- "9000:5000"
 # depends_on 设定了依赖，这里 redisdemo 会先于 pyweb 启动
 # 但是如果 redisdemo 启动时间长于 pyweb
 # 那么 pyweb 运行的时候 redisdemo 未必可用
 depends_on:
- redisdemo

  redisdemo:
 # 每个服务必须用 image 指定镜像名或者从 Dockerfile 中 build
 # 这里用 image 指定镜像，redis:alpine 是 redis 项目的官方 Docker 镜像
 image: "redis:alpine"

```

```dockerfile
# Dockerfile
FROM ubuntu:18.04

RUN apt update
RUN apt -y install python3 python3-pip
RUN pip3 install flask redis

COPY app.py /code/app.py

WORKDIR /code

CMD ["python3", "app.py"]

```

## 重新构建镜像

更改`app.py`的内容后，再次运行`docker-compose up`会发现并未重新构建镜像

因为`Dockerfile`并未修改，所以docker复用了已有的镜像，所以修改并未生效

这时候应该重新构建镜像并运行，或者加上 `--build`参数强制build

```bash
docker-compose up --build
```

## 共享目录

如果每次修改都要重新build再启动容器会比较繁琐

可以用共享目录的方式来直接修改程序文件

```yml
# docker-compose.yml
version: '3'

services:
  pyweb:
 build: .
 ports:
- "9000:5000"
 depends_on:
- redisdemo
 # volumes参数把当前目录挂载到容器的 /code
 # docker-compose 的配置才支持相对路径的挂载
 volumes:
- .:/code
  redisdemo:
 image: "redis:alpine"
```

```dockerfile
# Dockerfile
FROM ubuntu:18.04

RUN apt update
RUN apt -y install python3 python3-pip
RUN pip3 install flask redis

# COPY app.py /code/app.py #删除了此行

WORKDIR /code

CMD ["python3", "app.py"]
```

```python
# app.py
from flask import Flask
from redis import Redis


app = Flask(__name__)
# redisdemo 是 compose 中创建的主机名，由 docker-compose.yml 中指定
# compose 会给每个容器提供 DNS 服务保证容器间互相访问
redis = Redis(host='redisdemo', port=6379)


@app.route('/')
def index():
 count = redis.incr('hits')
 return 'views {}'.format(count)


if __name__ == "__main__":
 app.run(host="0.0.0.0", debug=True)
```



## 服务器部署

在本机开发，在服务器测试或部署

`app.py`, `Dockerfile`, `docker-compose.yml`与上面相同

在本机执行`upload-and-run.sh`

```bash
sh upload-and-run.sh
```

```bash
# upload-and-run.sh
# 上传项目到服务器
scp -r . ubuntu@111.111.111.111:/tmp/compose3

# 在服务器重启项目
ssh ubuntu@111.111.111.111 'sh /tmp/compose3/run.sh'
```

```bash
# run.sh
cd /tmp/compose3
sudo docker-compose down
sudo docker-compose up -d
```

## 更换国内源

docker镜像源可替换为中科大镜像源

https://lug.ustc.edu.cn/wiki/mirrors/help/docker

新版的 Docker 使用 `/etc/docker/daemon.json`（Linux） 或者 `%programdata%\docker\config\daemon.json`（Windows） 来配置 Daemon。

镜像地址 https://docker.mirrors.ustc.edu.cn

在该配置文件中加入（没有该文件的话，先建一个）：

```json
{
  "registry-mirrors": ["https://docker.mirrors.ustc.edu.cn"]
}
```

重启docker

```shell
service restart docker
```

### apt 源

https://opsx.alibaba.com/mirror（阿里云）

将网址另存为sources.list

### pip源

```
# /root/.pip/pip.conf
[global]
trusted-host=mirrors.aliyun.com
index-url=https://mirrors.aliyun.com/pypi/simple
```

### npm源

https://npm.taobao.org

```bash
npm install -g cnpm --registry=https://registry.npm.taobao.org
```

### 修改Dockerfile文件

```dockerfile
FROM ubuntu:18.04

# 使用阿里云的 apt 源
COPY sources.list /etc/apt/sources.list
RUN apt update
RUN apt -y install python3 python3-pip

# 使用阿里云的 pip 源
COPY pip.conf /root/.pip/pip.conf
RUN pip3 install flask


CMD ["python3"]
```

测试安装速度

```bash
docker build -t customimage .
```

## 镜像的选择

alpine镜像上官方推荐的打包基础镜像，很小

```
python:3.7-alpine3.8 # 3.7-alpine3.8是标签
----
python		# 自动补成latest标签
python:latest
```

使用镜像时可以考虑：

1. 使用专有镜像（比如`python`镜像）而不是在`ubuntu`镜像上安装软件

2. 使用基于`alpine`打包的镜像

## 镜像的分层构建和缓存

docker会对Dockerfile中执行指令的结果生成缓存，再次构建镜像的时候，如果没有改动就会复用缓存结果。

指令的顺序很重要，前面的指令有改变，后面会全部重新build。所以应该把最不易更改的指令放在前面。

**注意：**COPY指令中的源文件如果修改，也会被认为缓存失败

将下面命令保存为`docker.txt`

```
FROM ubuntu:18.04
COPY sources.list /etc/apt/sources.list
RUN apt update
```

构建命令

```bash
docker build -t imagecache -f docker.txt .
```

使用 `-f` 参数指定构建镜像的文件名

## 端口绑定

默认的`8000:3000`形式实际上是`0.0.0.0:8000:3000`，它表示任意机器都能访问本机的`8000`端口

很多时候我们不希望暴露服务端口，希望只有本机能够访问，这时候应该写成`127.0.0.1:8000:3000`



查看日志，在项目中

使用`docker-compose logs`可以查看一个Compose项目的日志

使用`docker-compose logs pyweb`可以只查看某个特定服务



## compose的多文件和覆盖配置

当我们使用`docker-compose up`启动compose项目的时候

实际上相当于

```bash
docker-compose -f docker-compose.yml up
```

我们可以使用多个不同的compose配置文件来实现不同的启动方式

我们可以用`init.yml`用于初始化

我们可以用`debug.yml`用于启动调试模式

还可以使用多个配置文件的组合方式

```bash
docker-compose -f docker-compose.yml -f debug.yml up
docker-compose -f docker-compose.yml -f test.yml up
```

```yml
# debug.yml
version: '3'

services:
  pyweb:
 ports:
- "127.0.0.1:9000:5000"
```

```yml
# docker-compose.yml
version: '3'

services:
  pyweb:
 build: .
 depends_on:
- redisdemo
 volumes:
- .:/code
  redisdemo:
 image: "redis:alpine"
```

```yml
# test.yml
version: '3'

services:
  pyweb:
 ports:
- "8000:5000"
```

## 开发部署

项目的开发和部署需要不同的设置，通常会使用不同的环境变量来配置环境



compose的配置文件可以用两种方式

```bash
docker-compose -f docker-compose.
```

```dockerfile
# Dockerfile
FROM ubuntu:18.04
WORKDIR /code
CMD ["bash", "/code/echo_env.sh"]
```

```sh
# echo_env.sh
echo "读取环境变量 $NAME"
```

```yaml
# prod.yml
version: '3'

services:
  bash:
 # environment 参数用于指定环境变量
 environment:
- PRODUCTION
- NAME=prod.yml

```

```yaml
# debug.yml
version: '3'

services:
  bash:
 # 可以使用 env_file 的形式从文件中读取环境变量
 env_file:
- a.env
- b.env
```

```
# a.env
NAME="a.env in debug.yml"
```

```
# b.env
ENV_FILE=b.env
```

## 其他用法

用Docker来发布C/C++或者其他平台相关的软件

用于快速、方便安装一些服务

比如`gogs`服务，官方文档的安装方法比Docker麻烦很多

https://gogs.io/docs/installation

如果使用docker

```bash
docker run -p 3000:3000 gogs/gogs:latest
```


## 安装代码托管服务

`gogs`是一个类似`github`的代码托管服务

它简单方便易于使用，我们使用它进行源代码管理

1. 将本目录下的`docker-compose.yml`上传到服务器的`/root/gogs/docker-compose.yml`

2. 在服务器的`/root/gogs`中启动服务`docker-compose up -d`

3. 访问服务器的3000端口并初始化服务

```yaml
# docker-compose.yml
version: '3'

services:
 gogs:
image: gogs/gogs:0.11.53
restart: always
volumes:
  # 将 gogs 的数据文件存储在本机
  - "./data/gogs:/data"
ports:
  - "3000:3000"
environment:
  - "RUN_CROND=true"
depends_on:
  - postgres
 postgres:
image: postgres:9.5
restart: always
volumes:
  # 将数据库文件存储到本机，以免丢失
  - "./data/postgresql:/var/lib/postgresql"
ports:
  - "127.0.0.1:5432:5432"
environment:
  # 数据库的连接信息
  - "POSTGRES_USER=admin"
  - "POSTGRES_PASSWORD=123456"
  - "POSTGRES_DB=gogs"

```

安装时，数据库主机是`postgres:5432`，应用URL也要修改

## 安装持续集成服务器

drone是一个轻便简洁的持续集成服务器程序

持续集成服务器的功能是在我们提交代码后自动拉取，自动运行预先设置好的测试以确保及早发现代码中的bug

在代码测试失败后，我们可以配置微信、短信、邮件等方式接收通知以便及时修复bug

在代码测试成功后，我们可以配置自动部署到线上生产环境，这个过程又叫持续部署



1. 将`docker-compose.yml`上传到服务器的`/root/drone/docker-compose.yml`
2. 在服务器的`/root/drone`中启动服务`docker-compose up -d`



由于`docker-compose.yml`中配置了使用`gogs`

所以现在可以访问服务器的8000端口并使用`gogs`的账户登录

它会登录后自动同步我们存放在`gogs`中的项目

http://readme.drone.io/

```yml
# docker-compose.yml
version: '3'

services:
  server:
 image: drone/drone:0.8.6
 ports:
- 8000:8000
 volumes:
- ./data/drone:/var/lib/drone/
 restart: always
 environment:
# false 表示禁止注册
- DRONE_OPEN=false
# DRONE_ADMIN 配置的用户作为管理员
- DRONE_ADMIN=admin123
# 本机主机名
- DRONE_HOST=http://111.111.111.111
# 随机输入一个字符串
- DRONE_SECRET=random_string_123
# 使用 gogs 服务
- DRONE_GOGS=true
# gogs 的地址
- DRONE_GOGS_URL=http://111.111.111.111:3000
# gogs 的 git 用户名
- DRONE_GOGS_GIT_USERNAME=admin123
# 密码
- DRONE_GOGS_GIT_PASSWORD=123
# 私有模式
- DRONE_GOGS_PRIVATE_MODE=true
# 关闭 ssl 验证（我们没有配置 https 访问）
- DRONE_GOGS_SKIP_VERIFY=true
  agent:
 image: drone/agent:0.8.6
 command: agent
 restart: always
 depends_on:
- server
 volumes:
# 这样才可以在容器中使用宿主机的 Docker 服务
- /var/run/docker.sock:/var/run/docker.sock
 environment:
# secret 和上面的 DRONE_SECRET 配置一致
- DRONE_SECRET=random_string_123
# 上面的 server 服务的 9000 端口
- DRONE_SERVER=server:9000

```

## 使用drone

首先在drone的网页中打开对仓库的监听

点开仓库的详细页面



drone使用 `.drone.yml`文件配置自动测试

如果drone监听了一个仓库，仓库的根目录下有 `.drone.yml` 文件

drone就会使用` .drone.yml `文件中定义的步骤测试代码并做一些自定义的操作

自定义的操作包括通知、自动部署等

```yml
# .drone.yml
# drone会先自动拉取代码，再按顺序执行pipline配置中定义的任务
# 代码拉取后，会使用 python:3.7-alpine3.8 镜像来执行项目目录下的 a.py 文件
pipeline:
  run:
 image: python:3.7-alpine3.8
 commands:
- python3 a.py
```

## 自动部署到生产服务器

生产服务器已经预先安装好了docker



要在测试成功后自动部署，最好使用ssh连接到生产服务器

所以要在生产服务器上生成RSA密钥并添加访问权限

```bash
# 生成无密码的公钥和私钥
ssh-keygen -t rsa -f /tmp/id_rsa
# 添加公钥，以便让这个私钥可以访问生产服务器
cat /tmp/id_rsa.pub >> ~/.ssh/authorized_keys
```

ssh访问生产服务器的配置见` .drone.yml `文件

配置完成后，测试一下，可以看到现在已经可以执行任意命令了



要实现自动部署，可以选择在生产服务器上使用git来拉取新代码

那么首先去生产服务器初始化一次，代码目录为 `/home/ubuntu/todo`

```
cd /home/ubuntu
git clone http://111.111.111.111:3000/admin123/todo.git
```

以后每次直接去代码目录` git pull`再重新运行项目即可

```yaml
# .drone.yml
pipeline:
  run:
 image: python:3.7-alpine3.8
 commands:
- python3 test.py
  deploy:
 image: appleboy/drone-ssh
 host: 222.222.222.222 # 生产服务器
 username: ubuntu
 # secrets 的 ssh_key 是固定用法
 # 这个参数是在drone中对应仓库的secrets选项中添加的，名字必须是ssh_key
 secrets: [ ssh_key ]
 port: 22
 script:
- echo "hello" > /tmp/hello.drone

```

## drone实现自动部署

要实现自动部署，可以实现在生产服务器上使用git来拉取新代码

那么首先去生产服务器初始化一次，代码目录为` /home/ubuntu/todo`

```bash
cd /home/ubuntu
git clone http://111.111.111.111:3000/admin123/todo.git
```

以后每次直接去代码目录` git pull` 再重新运行项目即可



部署项目的脚本如下

```yml
# .drone.yml
script:
  - cd /home/ubuntu/todo
  - git pull
  - sudo sh update.sh
```

```bash
# update.sh
# 重新构建镜像
docker build -t pywebimage .

# 删除容器
docker rm -f pyweb

# 启动容器
docker run -d -p 8080:5000 \
 --name pyweb \
 --mount type=bind,source="${PWD}",target=/code \
 pywebimage

```

```dockerfile
# Dockerfile
FROM python:3.7-alpine3.8

RUN pip3 install -i https://mirrors.aliyun.com/pypi/simple flask

WORKDIR /code

CMD ["python3", "app.py"]
```

```yml
# app.py
from flask import Flask


app = Flask(__name__)


@app.route('/')
def index():
 return 'Hello from drone'


if __name__ == "__main__":
 app.run(host="0.0.0.0", port='5000', debug=True)

```

部署成功后，访问链接使用

http://222.222.222.222:5000

## 其他操作

插件

http://plugins.drone.io

让整个构建步骤只在某些分支发生变化的时候执行

https://docs.drone.io/user-guide/pipeline/conditions/

让某一步动作在特定条件执行

https://docs.drone.io/config/pipeline/steps/

让drone支持github

https://0-8-0.docs.drone.io/install-for-github/